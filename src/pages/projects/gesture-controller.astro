---
import Layout from "../../layouts/Layout.astro";
import gestureDemo from "../../assets/images/deep-dives/gesture/up-down-use.gif";
import { Image } from "astro:assets";
---

<Layout title="Gesture Volume Controller | Sam Popham" noParticles>
  <section class="max-w-6xl mx-auto px-6 py-12">
    <div
      class="flex flex-col sm:flex-row sm:items-center sm:justify-between gap-4 mb-8"
    >
      <h1 class="text-4xl font-bold mb-0">
        Gesture Volume Controller - Deep Dive
      </h1>

      <a
        href="https://github.com/SPopham1/point-volume-system"
        target="_blank"
        rel="noopener noreferrer"
        class="inline-flex items-center gap-2 h-12 px-5 bg-gray-900 hover:bg-black text-white dark:bg-white dark:text-black dark:hover:bg-gray-200 rounded-lg font-semibold shadow-md transition whitespace-nowrap"
      >
        <svg
          xmlns="http://www.w3.org/2000/svg"
          viewBox="0 0 24 24"
          fill="currentColor"
          class="w-5 h-5 flex-shrink-0"
        >
          <path
            d="M12 2C6.48 2 2 6.58 2 12.26c0 4.54 2.87 8.39 6.84 9.75.5.09.68-.22.68-.49
    0-.24-.01-.88-.01-1.73-2.78.62-3.37-1.37-3.37-1.37-.45-1.18-1.11-1.5-1.11-1.5
    -.91-.63.07-.62.07-.62 1.01.07 1.54 1.05 1.54 1.05.9 1.57 2.36 1.12 2.94.86
    .09-.66.35-1.12.63-1.38-2.22-.26-4.56-1.13-4.56-5.05
    0-1.12.39-2.04 1.03-2.76-.1-.26-.45-1.3.1-2.72 0 0 .84-.27 2.75 1.05
    A9.3 9.3 0 0 1 12 6.84c.85.004 1.7.12 2.5.35
    1.9-1.32 2.74-1.05 2.74-1.05.55 1.42.2 2.46.1 2.72
    .64.72 1.03 1.64 1.03 2.76 0 3.93-2.34 4.78-4.57 5.04
    .36.32.68.95.68 1.92 0 1.39-.01 2.51-.01 2.85
    0 .27.18.59.69.49A10.27 10.27 0 0 0 22 12.26C22 6.58 17.52 2 12 2z"
          ></path>
        </svg>

        <span>View Source</span>
      </a>
    </div>

    <p class="text-gray-600 dark:text-gray-400 mb-6">
      A real-time computer vision system that uses MediaPipe hand tracking to
      map stable hand poses to operating system volume control, with live
      calibration and feedback for reliable gesture interaction.
    </p>

    <!-- Hero image -->
    <figure class="mb-12">
      <!--
        Image guidance:
        Complete gesture controller demo:
        - hand in view with landmark overlay, calibration controls, and volume feedback visible,
        - showcase the full workflow in one comprehensive screenshot or GIF.
      -->
      <Image
        src={gestureDemo}
        alt="Gesture volume controller in action"
        class="w-full rounded-lg shadow-lg"
      />
    </figure>

    <!-- Key features in text-only sections -->
    <div class="space-y-8">
      <article>
        <h2 class="text-2xl font-semibold mb-3">
          Hand Landmark Tracking & Confidence Filtering
        </h2>
        <p class="text-gray-600 dark:text-gray-400">
          The system uses MediaPipeâ€™s 21-point hand landmark model to track
          finger joints in real time. Each frame includes landmark confidence
          data, allowing low-confidence detections to be filtered out to reduce
          jitter and false triggers. Visual overlays show keypoints and skeletal
          connections so users can see exactly what the model is detecting.
        </p>
      </article>

      <article>
        <h2 class="text-2xl font-semibold mb-3">
          Gesture Calibration Interface
        </h2>
        <p class="text-gray-600 dark:text-gray-400">
          A background tray application allows users to calibrate gesture
          sensitivity and define mapping ranges between hand pose measurements
          and system volume. This calibration step compensates for camera
          placement, hand size variation, and lighting differences, making the
          interaction consistent across setups.
        </p>
      </article>

      <article>
        <h2 class="text-2xl font-semibold mb-3">
          Real-Time Gesture-to-Volume Mapping
        </h2>
        <p class="text-gray-600 dark:text-gray-400">
          Continuous pose measurements are converted into a smooth volume
          control signal using temporal smoothing to avoid sudden jumps. A
          minimal HUD overlay displays the live mapped volume level, providing
          immediate feedback and reinforcing the link between physical gesture
          and system response.
        </p>
      </article>
    </div>
  </section>
</Layout>
>
